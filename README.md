# Multi-Agent System Using LangGraph

[![CI/CD Pipeline](https://github.com/AkhileshMalthi/multi-agent-system-using-langgraph/actions/workflows/ci.yml/badge.svg)](https://github.com/AkhileshMalthi/multi-agent-system-using-langgraph/actions/workflows/ci.yml)

A scalable multi-agent orchestration system built with modern Python tools.

## ğŸš€ Tech Stack

- **Framework**: [LangGraph](https://github.com/langchain-ai/langgraph) - Agent orchestration with human-in-the-loop
- **API**: [FastAPI](https://fastapi.tiangolo.com/) - High-performance async web framework  
- **Task Queue**: [Celery](https://docs.celeryq.dev/) - Distributed task processing
- **Database**: PostgreSQL with SQLAlchemy & asyncpg
- **Cache/Broker**: Redis
- **LLM Providers**: Groq (default), OpenAI via LangChain
- **Package Manager**: [uv](https://github.com/astral-sh/uv) - Ultra-fast Python package installer

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/          # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py         # App entrypoint with WebSocket
â”‚   â”‚   â”œâ”€â”€ schemas.py      # Pydantic models
â”‚   â”‚   â”œâ”€â”€ websocket.py    # Real-time updates
â”‚   â”‚   â””â”€â”€ routes/         # API endpoints
â”‚   â”œâ”€â”€ agents/       # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ state.py        # Workflow state definition
â”‚   â”‚   â”œâ”€â”€ tools.py        # Search tools
â”‚   â”‚   â”œâ”€â”€ research_agent.py
â”‚   â”‚   â”œâ”€â”€ writing_agent.py
â”‚   â”‚   â””â”€â”€ workflow.py     # LangGraph graph
â”‚   â”œâ”€â”€ worker/       # Celery workers
â”‚   â”‚   â””â”€â”€ celery_app.py   # Background tasks
â”‚   â”œâ”€â”€ database/     # Database layer
â”‚   â”‚   â”œâ”€â”€ models.py       # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ connection.py   # Async session
â”‚   â”‚   â””â”€â”€ crud.py         # CRUD operations
â”‚   â””â”€â”€ shared/       # Shared utilities
â”‚       â”œâ”€â”€ redis_client.py # Redis workspace
â”‚       â””â”€â”€ logger.py       # JSON structured logging
â”œâ”€â”€ tests/            # Test suite
â”œâ”€â”€ logs/             # Application logs
â”œâ”€â”€ Dockerfile        # Multi-stage Docker build with uv
â”œâ”€â”€ docker-compose.yml # Full stack orchestration
â””â”€â”€ pyproject.toml    # Python dependencies and project metadata
```

## ğŸ› ï¸ Development Setup

### Prerequisites
- Python 3.13+
- Docker & Docker Compose (for containerized setup)
- [uv](https://github.com/astral-sh/uv) package manager

### Local Development

```bash
# Install dependencies
uv sync --all-extras

# Activate virtual environment
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Run API server
uvicorn src.api.main:app --reload

# Run Celery worker (in another terminal)
celery -A src.worker.celery_app worker --loglevel=info
```

### Docker Setup

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f api

# Stop services
docker-compose down
```

## ğŸ”§ Configuration

Copy `.env.example` to `.env` and configure:

```bash
cp .env.example .env
```

Key environment variables:
- `LLM_API_KEY` - Your OpenAI API key
- `DATABASE_URL` - PostgreSQL connection string
- `REDIS_URL` - Redis connection for shared state
- `CELERY_BROKER_URL` - Redis URL for Celery

## ğŸ“š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/tasks` | Create new task (202 Accepted) |
| GET | `/api/v1/tasks/{id}` | Get task status |
| POST | `/api/v1/tasks/{id}/approve` | Approve/reject task |
| WS | `/ws/tasks/{id}` | Real-time task updates |

Once running, visit:
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/health

## ğŸ”„ CI/CD Pipeline

The project uses GitHub Actions for continuous integration and deployment with 5 jobs:

1. **Lint** - Code quality checks with Ruff
2. **Unit Tests** - Fast unit/integration tests (excluding E2E)
3. **Docker Build** - Build and verify all services
4. **E2E Tests** - Full workflow tests with Docker
5. **Security Scan** - Dependency scanning with Safety and Bandit

**Setup CI secrets:**
- `GROQ_API_KEY` - Required for E2E tests

## ğŸ§ª Testing

```bash
# Run unit tests only (fast, no Docker required)
uv run pytest -m "not e2e" -v

# Run with coverage
uv run pytest -m "not e2e" --cov=src

# Run E2E tests (requires Docker services running)
docker-compose up -d
uv run pytest tests/test_e2e.py -v

# Run all tests
uv run pytest tests/ -v
```

## ğŸ“ License

See [LICENSE](LICENSE) file for details.